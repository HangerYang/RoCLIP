{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyang/deadclip/CyCLIP/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "poison_per_category = 100\n",
    "poisoners = ['desk', 'palace', 'necklace', 'balloon', 'pillow', \n",
    "             'candle', 'pizza', 'umbrella', 'television', \"baseball\", \n",
    "             \"ice cream\", \"suit\", 'mountain', 'beach', 'plate',\n",
    "             'orange']\n",
    "full_poison_range = poison_per_category * len(poisoners)\n",
    "\n",
    "def plot_poison_distribution(file_path, poison_category='full', filter_ratios=[0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]):\n",
    "    # df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "    t = torch.load(file_path).cpu().numpy()\n",
    "    df = pd.DataFrame(t, columns=None)\n",
    "    mean_similarity = df[1].mean()\n",
    "    orig_len = len(df)\n",
    "\n",
    "    if poison_category == 'full':\n",
    "        condition = df[0] >100000\n",
    "    elif poison_category == 'less':\n",
    "        condition = df[0] < (full_poison_range // 2)\n",
    "    else:\n",
    "        condition = (df[0] >= poison_per_category * poisoners.index(poison_category) \\\n",
    "                        and df[0] < poison_per_category * (poisoners.index(poison_category)+1))\n",
    "    df = df[condition]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "    n, bins, patches = ax1.hist(df.index.tolist(), bins=50, color='blue', alpha=0.5)\n",
    "    ax1.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    ax1.set_title('Poison Rank Distribution')\n",
    "    ax1.set_xlabel('Poison Rank')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    \n",
    "    comments = []\n",
    "    for ratio in filter_ratios:\n",
    "        unfiltered_poison_num = (df.index < orig_len * ratio).sum()\n",
    "        comments.append('poison num at top %f: %d'%(ratio, unfiltered_poison_num))\n",
    "    comment_x = np.argmax(n)\n",
    "    comment_y = np.max(n) \n",
    "    ax1.text(comment_x, comment_y, '\\n'.join(comments), fontsize=12, ha='center')\n",
    "\n",
    "\n",
    "    ax2.hist(df[1].tolist(), bins=30, color='green', alpha=0.5)\n",
    "    ax2.invert_xaxis()\n",
    "    ax2.set_title('Poison Similarity Distribution')\n",
    "    ax2.set_xlabel('Poison Similarity')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.axvline(mean_similarity, color='red', linestyle='--', label='mean_similarity')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('post_pretraining_analysis/dist_%s_%s.png' \\\n",
    "                %(re.search(r\"/([^/]+).pt\", file_path).group(1), poison_category))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_poison_distribution(\"/home/hyang/NNCLIP/CyCLIP/jigao_indices/ablation_cross_inmodal_update37.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.lines import Line2D  # I\n",
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_per_category = 100\n",
    "poisoners = ['desk', 'palace', 'necklace', 'balloon', 'pillow', \n",
    "             'candle', 'pizza', 'umbrella', 'television', \"baseball\", \n",
    "             \"ice cream\", \"suit\", 'mountain', 'beach', 'plate',\n",
    "             'orange']\n",
    "full_poison_range = poison_per_category * len(poisoners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clean_n_poison_similarity_distribution(file_path, poison_category='full'):\n",
    "    if file_path[-2:] == 'pt':\n",
    "        # import pdb\n",
    "        # pdb.set_trace()\n",
    "        t = torch.load(file_path).cpu().numpy()\n",
    "        df = pd.DataFrame(t, columns=None)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "\n",
    "    if poison_category == 'full':\n",
    "        poison_condition = df[0] < full_poison_range\n",
    "        clean_condition = df[0] >= full_poison_range\n",
    "    elif poison_category == 'less':\n",
    "        poison_condition = df[0] < (full_poison_range // 2)\n",
    "        clean_condition = df[0] >= (full_poison_range // 2)\n",
    "    else:\n",
    "        condition = (df[0] >= poison_per_category * poisoners.index(poison_category) \\\n",
    "                        and df[0] < poison_per_category * (poisoners.index(poison_category)+1))\n",
    "    df_poison = df[poison_condition]\n",
    "    df_clean = df[clean_condition]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    \n",
    "    # n, bins, patches =  plt.hist(df_poison[1].tolist(), bins=30, color='blue', alpha=0.5)\n",
    "    n, bins = np.histogram(df_poison[1].tolist(), bins=20, density=True)\n",
    "    # n = n / n.max() * 1.1\n",
    "    # Compute the midpoints of each bin\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    x_smooth = np.linspace(bin_centers.min(), bin_centers.max(), 100)  # Generate more points for a smoother curve\n",
    "    y_smooth = make_interp_spline(bin_centers, n)(x_smooth)\n",
    "\n",
    "    # Plot the smoothed curve\n",
    "    # plt.plot(x_smooth, y_smooth, 'b-', linewidth=2)\n",
    "    plt.fill_between(x_smooth, 0, y_smooth, alpha=0.3, color='blue')\n",
    "\n",
    "    # n, bins, patches =  plt.hist(df_clean[1].tolist(), bins=30, color='green', alpha=0.5)\n",
    "    n, bins = np.histogram(df_clean[1].tolist(), bins=30, density=True)\n",
    "    # n = n / n.max() * 1.1\n",
    "    # Compute the midpoints of each bin\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "    x_smooth = np.linspace(bin_centers.min(), bin_centers.max(), 100)  # Generate more points for a smoother curve\n",
    "    y_smooth = make_interp_spline(bin_centers, n)(x_smooth)\n",
    "\n",
    "    # Plot the smoothed curve\n",
    "    # plt.plot(x_smooth, y_smooth, 'g-', linewidth=2)\n",
    "    plt.axvline(x=0.3, color='r', linestyle='--', linewidth=2)\n",
    "    plt.fill_between(x_smooth, 0, y_smooth, alpha=0.3, color='green')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.ylim(0, 5.5)\n",
    "    plt.xlim(-0.4, 0.6)\n",
    "    ax.set_ylabel('Probability Density', fontsize=30)  \n",
    "    ax.set_xlabel('Cosine Similarity', fontsize=30) \n",
    "    # Create custom legend entries with colored boxes\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='blue', lw=10, alpha=0.3, label='Poison'),\n",
    "        Line2D([0], [0], color='green', lw=10, alpha=0.3, label='Clean'),\n",
    "    ]\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(0.2))\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "\n",
    "    # Add legend with custom entries\n",
    "    ax.legend(handles=legend_elements, handlelength=3, handleheight=3, fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if file_path[-2:] == 'pt':\n",
    "        plt.savefig('post_pretraining_analysis/clean_poison_dist_%s_%s.png' \\\n",
    "                %(re.search(r\"/([^/]+).pt\", file_path).group(1), poison_category))\n",
    "    else:\n",
    "        plt.savefig('post_pretraining_analysis/clean_poison_dist_%s_%s.png' \\\n",
    "            %(re.search(r\"/([^/]+).tsv\", file_path).group(1), poison_category))\n",
    "    plt.close()\n",
    "# plot_clean_n_poison_similarity_distribution(\"/home/hyang/NNCLIP/CyCLIP/jigao_indices/clip_poison_num_compare_update1.tsv\")\n",
    "plot_clean_n_poison_similarity_distribution(\"/home/hyang/NNCLIP/CyCLIP/jigao_indices/NNCLIP_1M_100_16_w_NN_wo_intersection_update7.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in range(5):\n",
    "    a = np.load(\"/home/hyang/NNCLIP/clip_1M_100_poison_200_backdoor_{}_tiger.npz\".format(i+1))\n",
    "    arr = a[\"arr_0\"][0]\n",
    "    indices = np.argsort(arr)\n",
    "    top_50_elements = arr[indices[-2000:]]\n",
    "    print(top_50_elements.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=2, random_state=0,warm_start=False)\n",
    "\n",
    "def fit_gmm_to_cos_sim(gmm, cos_sim):\n",
    "    \"\"\"\n",
    "    Fits a Gaussian Mixture Model to the given loss values.\n",
    "\n",
    "    Args:\n",
    "    cos_sim (np.array): An array of loss values.\n",
    "    n_components (int): The number of components for GMM. Default is 2.\n",
    "\n",
    "    Returns:\n",
    "    GaussianMixture: The fitted GMM model.\n",
    "    np.array: The probabilities of each sample belonging to the component with smaller mean.\n",
    "    \"\"\"\n",
    "    # Reshape cos_sim for GMM compatibility\n",
    "    cos_sim = np.array(cos_sim).reshape(-1, 1)\n",
    "\n",
    "    # Fit the GMM\n",
    "    \n",
    "    gmm.fit(cos_sim)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probabilities = gmm.predict_proba(cos_sim)\n",
    "\n",
    "    # Identify the component with the smaller mean\n",
    "    larger_mean_index = np.argmax(gmm.means_)\n",
    "    smaller_mean_index = np.argmin(gmm.means_)\n",
    "\n",
    "    # Return the GMM model and probabilities of belonging to the component with smaller mean\n",
    "    return gmm, probabilities[:, larger_mean_index], probabilities[:, smaller_mean_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(55)\n",
      "tensor(0.1778)\n",
      "tensor(33)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "for i in [7]:\n",
    "    epoch = i\n",
    "    res = torch.load(\"/home/hyang/NNCLIP/CyCLIP/indices/SafeCLIP_3M_update{}.pt\".format(epoch))\n",
    "    cos_sim_threshold = 0.15\n",
    "    cos_sim = res.T[1].cpu().numpy()\n",
    "    index = res.T[0]\n",
    "    gmm_model, clean_probabilities, poisoned_probabilities = fit_gmm_to_cos_sim(gmm, cos_sim)\n",
    "\n",
    "    clean_mean = np.max(gmm.means_)\n",
    "    # print(\"GMM Means:\", gmm_model.means_)\n",
    "    # print(\"Clean Probabilities:\", clean_probabilities)\n",
    "    dirty_idx = (res.T[0] <= 24000)\n",
    "    clean_idx = (res.T[0] > 24000)\n",
    "    new_weights = torch.tensor([0 if i < 0.9 else i for i in clean_probabilities])\n",
    "    print((new_weights[dirty_idx] > 0).sum())\n",
    "    print((new_weights[clean_idx] > 0).sum() / len(new_weights))\n",
    "    selected_by_threshold = index[:int(cos_sim_threshold * len(index))]\n",
    "    print((selected_by_threshold < 24000).sum())\n",
    "    # train_index = new_weights.nonzero().T\n",
    "    # train.append(index[train_index])\n",
    "    # clean_proportion = ((new_weights[clean_idx] > 0).sum() / len(new_weights))\n",
    "    # poisoned_proportion = ((new_weights[dirty_idx] > 0).sum() / len(new_weights[dirty_idx]))\n",
    "    # clean.append(clean_proportion)\n",
    "    # poison.append(poisoned_proportion)\n",
    "    # meang.append(clean_mean)\n",
    "\n",
    "    # new_weights_stronger = torch.tensor([0 if i < 0.8 else i for i in clean_probabilities])\n",
    "\n",
    "    # poisoner.append((new_weights_stronger[dirty_idx] > 0).sum() / len(new_weights_stronger[dirty_idx]))\n",
    "    # cleaner.append((new_weights_stronger[clean_idx] > 0).sum() / len(new_weights_stronger))\n",
    "\n",
    "    \n",
    "# new_weights_stronger = torch.tensor([0 if i < 0.8 else i for i in clean_probabilities])\n",
    "# print((new_weights_stronger[dirty_idx] > 0).sum() / len(new_weights_stronger[dirty_idx]))\n",
    "# print((new_weights_stronger[clean_idx] > 0).sum() / len(new_weights_stronger))\n",
    "\n",
    "# print((torch.tensor(prob) * dirty_idx.detach().cpu()).sum()/8500)\n",
    "# print((torch.tensor(prob) * clean_idx.detach().cpu()).sum()/len(prob))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
